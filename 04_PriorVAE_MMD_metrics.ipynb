{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PriorVAE: testing MMD (and in general different loss functions)\n",
    "\n",
    "For a 1D GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import time\n",
    "import dill\n",
    "from flax import serialization\n",
    "\n",
    "# Numpyro\n",
    "import numpyro\n",
    "from numpyro.infer import MCMC, NUTS, init_to_median, Predictive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyro.set_host_device_count(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reusable.kernels import esq_kernel, rbf_kernel\n",
    "\n",
    "args = {\n",
    "    # GP prior configuration\n",
    "    \"n\": 100,\n",
    "    \"gp_kernel\": esq_kernel,\n",
    "    \"rng_key\": random.PRNGKey(2),\n",
    "}\n",
    "args.update({ # so we can use the definition of n to define x\n",
    "    \n",
    "    \"x\": jnp.arange(0, 1, 1/args[\"n\"]),\n",
    "\n",
    "    # VAE configuration\n",
    "    \"hidden_dim1\": 35,\n",
    "    \"hidden_dim2\": 32,\n",
    "    \"latent_dim\": 30,\n",
    "    \"vae_var\": 0.1,\n",
    "\n",
    "    \"mmd_kernel\": lambda x,z: rbf_kernel(x,z, 4.0),\n",
    "\n",
    "    # learning\n",
    "    \"num_epochs\": 200,\n",
    "    \"learning_rate\": 1.0e-4,\n",
    "    \"batch_size\": 200,\n",
    "    \"train_num_batches\": 500,\n",
    "    \"test_num_batches\": 1,\n",
    "\n",
    "    # MCMC parameters\n",
    "    \"num_warmup\": 1000,\n",
    "    \"num_samples\": 1000,\n",
    "    \"thinning\": 1,\n",
    "    \"num_chains\": 3,\n",
    "\n",
    "    \"pretrained_vae\": False\n",
    "\n",
    "\n",
    "})\n",
    "\n",
    "rng_key, _ = random.split(random.PRNGKey(4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVI to learn VAE parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args[\"pretrained_vae\"]:\n",
    "    from reusable.gp import OneDGP\n",
    "    from reusable.train_nn import gen_gp_batches\n",
    "\n",
    "    \n",
    "    rng_key, rng_key_train, rng_key_test = random.split(rng_key, 3)\n",
    "\n",
    "    train_draws = gen_gp_batches(args[\"x\"], OneDGP, args[\"gp_kernel\"], args[\"train_num_batches\"], args[\"batch_size\"], rng_key_train)\n",
    "    test_draws = gen_gp_batches(args[\"x\"], OneDGP, args[\"gp_kernel\"], 1, args[\"test_num_batches\"]* args[\"batch_size\"], rng_key_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reusable.vae import VAE\n",
    "from reusable.train_nn import SimpleTrainState\n",
    "import optax\n",
    "\n",
    "rng_key, rng_key_init, rng_key_train = random.split(rng_key, 3)\n",
    "\n",
    "module = VAE(\n",
    "    hidden_dim1=args[\"hidden_dim1\"],\n",
    "    hidden_dim2=args[\"hidden_dim2\"],\n",
    "    latent_dim=args[\"latent_dim\"],\n",
    "    out_dim=args[\"n\"],\n",
    "    conditional=False,\n",
    ")\n",
    "params = module.init(rng_key, jnp.ones((args[\"n\"],)))[\"params\"]  # initialize parameters by passing a template image\n",
    "tx = optax.adam(args[\"learning_rate\"])\n",
    "state = SimpleTrainState.create(apply_fn=module.apply, params=params, tx=tx, key=rng_key_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "import jax\n",
    "\n",
    "from reusable.vae import vae_sample\n",
    "from flax.core.frozen_dict import freeze\n",
    "from functools import partial\n",
    "\n",
    "from reusable.mmd import mmd\n",
    "\n",
    "@jax.jit\n",
    "def RCL(y, reconstructed_y, mean, log_sd):\n",
    "    \"\"\"reconstruction loss, averaged over the datapoints (not summed)\"\"\"\n",
    "    return  jnp.sum(optax.l2_loss(reconstructed_y, y)) # 1/y.shape[0] *\n",
    "\n",
    "@jax.jit\n",
    "def KLD(y, reconstructed_y, mean, log_sd):\n",
    "    \"\"\"KL divergence between the distribution N(mean, log_sd) and a standard normal.\n",
    "    e.g. see https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Multivariate_normal_distributions\"\"\"\n",
    "    return -0.5 * jnp.sum(1 + log_sd - jnp.power(mean, 2) - jnp.exp(log_sd))\n",
    "\n",
    "@jax.jit\n",
    "def MMD(y, reconstructed_y, mean, log_sd):\n",
    "    return mmd(y, reconstructed_y, args[\"mmd_kernel\"])\n",
    "\n",
    "@jax.jit\n",
    "def rcl_kld(*args):\n",
    "    return RCL(*args) + KLD(*args)\n",
    "\n",
    "@jax.jit\n",
    "def rcl_kld_50mmd(*args):\n",
    "    return RCL(*args) + KLD(*args) + 50* MMD(*args)\n",
    "\n",
    "@jax.jit\n",
    "def kld_50mmd(*args):\n",
    "    return 50* MMD(*args) + KLD(*args)\n",
    "\n",
    "\n",
    "def compute_epoch_metrics(final_state: SimpleTrainState, test_samples, train_samples, train_output, test_output):\n",
    "\n",
    "    current_metric_key = jax.random.fold_in(key=final_state.key, data=2 * final_state.step + 1)\n",
    "\n",
    "    vae_draws = Predictive(vae_sample, num_samples=args[\"batch_size\"])(\n",
    "        current_metric_key,\n",
    "        hidden_dim1=args[\"hidden_dim1\"],\n",
    "        hidden_dim2=args[\"hidden_dim2\"],\n",
    "        latent_dim=args[\"latent_dim\"],\n",
    "        out_dim=args[\"n\"],\n",
    "        decoder_params=freeze({\"params\": final_state.params[\"VAE_Decoder_0\"]}),\n",
    "    )[\"f\"]\n",
    "\n",
    "    metrics = {\n",
    "        \"train_mmd\": mmd(vae_draws, train_samples[-1], args[\"mmd_kernel\"]),\n",
    "        \"test_mmd\": mmd(vae_draws, test_samples[-1], args[\"mmd_kernel\"]),\n",
    "        \"train_kld\": KLD(*train_output),\n",
    "        \"test_kld\": KLD(*test_output),\n",
    "        \"train_rcl\": RCL(*train_output),\n",
    "        \"test_rcl\": RCL(*test_output)\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reusable.train_nn import run_training\n",
    "import matplotlib.pyplot as plt\n",
    "from plotting.plots import plot_training\n",
    "\n",
    "from reusable.vae import vae_sample\n",
    "from plotting.plots import compare_draws\n",
    "import jax.random as random\n",
    "from numpyro.infer import Predictive\n",
    "from reusable.gp import OneDGP\n",
    "from reusable.util import decoder_filename, get_savepath\n",
    "\n",
    "\n",
    "\n",
    "_, rng_key_predict = random.split(random.PRNGKey(2))\n",
    "\n",
    "plot_gp_predictive = Predictive(OneDGP, num_samples=1000)\n",
    "gp_draws = plot_gp_predictive(rng_key_predict, x=args[\"x\"], gp_kernel = args[\"gp_kernel\"], jitter=1e-5)['y']\n",
    "\n",
    "\n",
    "saved_states  = {}\n",
    "if not args[\"pretrained_vae\"]:\n",
    "    loss_fns = [rcl_kld_50mmd, kld_50mmd]\n",
    "    for loss_fn in loss_fns:\n",
    "        print( loss_fn.__name__)\n",
    "        final_state, metrics_history = run_training(\n",
    "            loss_fn, compute_epoch_metrics, args[\"num_epochs\"], train_draws, test_draws, state\n",
    "        )\n",
    "        saved_states[loss_fn.__name__] = final_state\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(24, 4))\n",
    "        for i,t in enumerate([\"loss\", \"mmd\", \"kld\", \"rcl\"]):\n",
    "\n",
    "            plot_training(\n",
    "                jnp.array(metrics_history[\"test_\"+t]).flatten(),\n",
    "                jnp.array(metrics_history[\"train_\"+t]).flatten(),\n",
    "                f\"Test/train {t} for \" + loss_fn.__name__,\n",
    "                t,\n",
    "                axs[i],\n",
    "            )\n",
    "        plt.show()\n",
    "        print(metrics_history)\n",
    "        plot_vae_predictive = Predictive(vae_sample, num_samples=1000)\n",
    "        vae_draws = plot_vae_predictive(\n",
    "            rng_key_predict,\n",
    "            hidden_dim1=args[\"hidden_dim1\"],\n",
    "            hidden_dim2=args[\"hidden_dim2\"],\n",
    "            latent_dim=args[\"latent_dim\"],\n",
    "            out_dim=args[\"n\"],\n",
    "            decoder_params=freeze({\"params\": final_state.params[\"VAE_Decoder_0\"]}),\n",
    "        )[\"f\"]\n",
    "            \n",
    "\n",
    "\n",
    "        compare_draws(args[\"x\"], gp_draws, vae_draws, \"GP priors we want to encode\", \"Priors learnt by VAE w/ loss\" + loss_fn.__name__, '$y=f_{GP}(x)$', '$y=f_{VAE}(x)$', save_path=\"gen_plots/01_prior_comp.png\")\n",
    "        plt.show()\n",
    "\n",
    "        file_path = f'{get_savepath()}/{decoder_filename(\"04\", args, suffix=loss_fn.__name__)}'\n",
    "\n",
    "        if not args[\"pretrained_vae\"]:\n",
    "            decoder_params = state.params[\"VAE_Decoder_0\"]\n",
    "\n",
    "            decoder_params = freeze({\"params\": decoder_params})\n",
    "            args[\"decoder_params\"] = decoder_params\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(serialization.to_bytes(decoder_params))\n",
    "\n",
    "        file_path = f'{get_savepath()}/{decoder_filename(\"04\", args, suffix=loss_fn.__name__+\"_metrics_hist\")}'\n",
    "\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(dill.dump(metrics_history))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note \n",
    "that the jax fori_loop MMD definition is the same as the original one that generates the kernel matrices\n",
    "\n",
    "\n",
    "(Run the following cell to check - takes lots of time and memory!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reusable.mmd import mmd, orig_mmd\n",
    "#print(MMD(train_draws[1], test_draws[0], 0,0))\n",
    "\n",
    "# print(orig_mmd(train_draws[1], test_draws[0], args[\"mmd_kernel\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_numpyro_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21f1de7450aa0e66996400abe50a1a33510e029368463064840984274474dc01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
